{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "features=torch.randn((1,5))\n",
    "weights=torch.rand_like(features)\n",
    "bias=torch.randn((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2868, 0.2063, 0.4451, 0.3593, 0.7204]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6140)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(torch.sum(torch.mm(features,weights.resize_(5,1)) + bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d6b478d830>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "features=torch.randn(1,3)\n",
    "n_input=features.shape[1]\n",
    "n_hidden=2\n",
    "n_output=1\n",
    "W1=torch.randn(n_input,n_hidden)\n",
    "W2=torch.randn(n_hidden,n_output)\n",
    "B1=torch.randn(1,n_hidden)\n",
    "B2=torch.randn(1,n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3171]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = sigmoid(torch.mm(features,W1) +B1)\n",
    "op = sigmoid(torch.mm(h,W2) +B2 )\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import helper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms\n",
    "\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,),(0.5,)),\n",
    "                              ])\n",
    "\n",
    "trainset=datasets.MNIST('MNIST_data/',download=True,train=True,transform=transform)\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images,labels=dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ad761c288>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(),cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "print((images.resize_(64,784)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=images.view(images.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=torch.randn(784,256)\n",
    "b1=torch.randn(256)\n",
    "\n",
    "w2=torch.randn(256,10)\n",
    "b2=torch.randn(10)\n",
    "\n",
    "h=sigmoid(torch.mm(inputs,w1)+b1)\n",
    "out=torch.mm(h,w2)+b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "probabilities = softmax(out)\n",
    "print(probabilities.shape)\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(784,256)\n",
    "        self.output = nn.Linear(256,10)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.hidden(x)\n",
    "        x=self.sigmoid(x)\n",
    "        x=self.output(x)\n",
    "        x=self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Networknow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784,128)\n",
    "        self.hidden2 = nn.Linear(128,64)\n",
    "        self.output = nn.Linear(64,10)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.hidden1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.hidden2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.output(x)\n",
    "        x=self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Networknow(\n",
       "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Networknow()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,),(0.5,)),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2980, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10))\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "images,label=next(iter(trainloader))\n",
    "images=images.view(images.shape[0],-1)\n",
    "logits=model(images)\n",
    "loss=criterion(logits,label)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3010, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images,label=next(iter(trainloader))\n",
    "images=images.view(images.shape[0],-1)\n",
    "logits=model(images)\n",
    "loss=criterion(logits,label)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1151,  1.3497],\n",
      "        [ 0.2478, -1.6208]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0132, 1.8216],\n",
      "        [0.0614, 2.6271]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000002393AD10A48>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1308, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0576,  0.6748],\n",
      "        [ 0.1239, -0.8104]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0576,  0.6748],\n",
      "        [ 0.1239, -0.8104]])\n",
      "tensor([[-0.0576,  0.6748],\n",
      "        [ 0.1239, -0.8104]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3266, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images,label=next(iter(trainloader))\n",
    "images=images.view(images.shape[0],-1)\n",
    "logits=model(images)\n",
    "loss=criterion(logits,label)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass:\n",
      " None\n",
      "After backward pass:\n",
      " tensor([[ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
      "        [-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        [-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before backward pass:\\n\",model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('After backward pass:\\n',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we know how to calculate losses and use those losses to calculate gradients now to use those gradient values to update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights - Parameter containing:\n",
      "tensor([[ 0.0188, -0.0161,  0.0271,  ...,  0.0096, -0.0342, -0.0194],\n",
      "        [-0.0105,  0.0262,  0.0290,  ..., -0.0167,  0.0019, -0.0041],\n",
      "        [-0.0204, -0.0342,  0.0042,  ...,  0.0143,  0.0049,  0.0081],\n",
      "        ...,\n",
      "        [-0.0303, -0.0157,  0.0119,  ..., -0.0353,  0.0313,  0.0019],\n",
      "        [ 0.0101, -0.0012,  0.0058,  ..., -0.0222, -0.0289, -0.0202],\n",
      "        [ 0.0218,  0.0249, -0.0040,  ...,  0.0135, -0.0098, -0.0097]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0040, -0.0040, -0.0040,  ..., -0.0040, -0.0040, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0022,  0.0022,  0.0022,  ...,  0.0022,  0.0022,  0.0022],\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial Weights -',model[0].weight)\n",
    "\n",
    "images,labels = next(iter(trainloader))\n",
    "images.resize_(64,784)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output=model.forward(images)\n",
    "loss=criterion(output,labels)\n",
    "loss.backward()\n",
    "print('Gradient -',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights- Parameter containing:\n",
      "tensor([[ 0.0188, -0.0161,  0.0271,  ...,  0.0096, -0.0342, -0.0194],\n",
      "        [-0.0105,  0.0262,  0.0290,  ..., -0.0167,  0.0019, -0.0041],\n",
      "        [-0.0203, -0.0341,  0.0042,  ...,  0.0143,  0.0049,  0.0081],\n",
      "        ...,\n",
      "        [-0.0303, -0.0157,  0.0119,  ..., -0.0353,  0.0312,  0.0019],\n",
      "        [ 0.0101, -0.0012,  0.0058,  ..., -0.0222, -0.0289, -0.0202],\n",
      "        [ 0.0218,  0.0249, -0.0040,  ...,  0.0135, -0.0098, -0.0097]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Updated weights-',model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9184634827855807\n",
      "Training loss: 0.8629738220782168\n",
      "Training loss: 0.5211439549382816\n",
      "Training loss: 0.42739707928921367\n",
      "Training loss: 0.3856481939300037\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    for image,label in trainloader:\n",
    "        image=image.view(image.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(image)\n",
    "        loss = criterion(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images,labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1,784)\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "ps = F.softmax(logits,dim=1)\n",
    "view_classify(img.view(1,28,28),ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
